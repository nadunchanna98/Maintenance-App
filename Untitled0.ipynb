{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1x+ZVevhaTcRDPkAhVc8F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadunchanna98/Maintenance-App/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LAB 03 2019E117"
      ],
      "metadata": {
        "id": "5yoAalDDsMsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Study the dataset ’Fashion-MNIST’ in Keras. Answer the following questions in relation to the above dataset."
      ],
      "metadata": {
        "id": "yZbJJDmFsUQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Find out whether it can be used for regression or classification."
      ],
      "metadata": {
        "id": "qeWaKZNcswxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   It is used fot classification."
      ],
      "metadata": {
        "id": "06f1jP7JtHXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) What is the size of the images?"
      ],
      "metadata": {
        "id": "xTjzs4EYtYyl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K5fyQi_mr4ML"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = train_images.shape[1:]  # Shape of the train_images excluding the number of samples\n",
        "print(\"Size of the images:\")\n",
        "image_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jyDBFbxtgTU",
        "outputId": "2c5a0b4c-230c-44ff-eb76-0e59f20bea6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the images:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) How many images are there in the train data?"
      ],
      "metadata": {
        "id": "qGFqvtrkuRb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_images = train_images.shape[0]\n",
        "print(\"Number of images in the train data:\",num_train_images)\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnpEFLvjuCR_",
        "outputId": "77b34065-67ff-486e-cfc2-bf52b6e8c975"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the train data: 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) State the number of images in test data."
      ],
      "metadata": {
        "id": "WvBACQoUu4fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_test_images = test_images.shape[0]\n",
        "print(\"Number of images in the test data:\", num_test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtq9FrThunHI",
        "outputId": "ae603ddc-dfc4-47fb-dec1-8b6f85dabd18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the test data: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) How many classes are there in the data? Write down those classes."
      ],
      "metadata": {
        "id": "gJb1jSBIvVN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set(train_labels))\n",
        "class_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Class labels:\", class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx0l6UDmvMWp",
        "outputId": "6d9c4cf9-3bef-408d-89ce-ed983acd333f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 10\n",
            "Class labels: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Load that dataset directly from Keras using Python."
      ],
      "metadata": {
        "id": "57g5AH7Gwh__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "3k_ncWzRvkzT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. View some images in training data, for example draw the 11th image in your training data."
      ],
      "metadata": {
        "id": "AWxX0sqCyp3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_images[100], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "6YTxuhn4ySOk",
        "outputId": "f973ba4a-3040-413c-b10d-6fc1f7832892"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAOhUlEQVR4nO3cyYuc9drH4V93dXe6O2bQTKIuRA4iuhIFgxshKycQRQQ3DggiRgVx40Jxr39E0I0rIwbBAXETkUDEqMQgwRg0GI1m1CQ9VA9n8XJu8EUOdd+mH+u017X2S9V5uro/qcW5R5aXl5cbALTWRv/uNwDA8BAFAIIoABBEAYAgCgAEUQAgiAIAQRQACGOD/ocjIyMr+T74G1V+tl3+fx6vuOKK9Obhhx9Oby677LL05uzZs+nNG2+8kd601trMzExpB/8xyO+tbwoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAgjywNeNnMQj7/qiSeeKO22b9+e3hw6dCi92b9/f3pz++23pze33XZbetNaa/v27UtvXnvttdJrZfV6vfRmcXFxBd4J/42DeACkiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQHAQb5Wp/JwG/Aj8wXPPPZfeXHXVVelNa629+OKLpd1q8+abb6Y3s7Oz6c3jjz+e3lSMjtb+Tbq0tHSJ38k/h4N4AKSIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgiupSV1dIZ2YmEhvWmttfn4+vbnzzjvTm3vuuSe9efbZZ9ObqvHx8fSm3++nN5VLn11e+dy9e3d6s2/fvvTm1VdfTW8qP6PWaj8n/o8rqQCkiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQHAQL6nyHMbGxtKbLo9+VY6mPfTQQ+nNwsJCetNa7flVX4vWPvvss/TmscceS28OHjyY3rTm8/BXOIgHQIooABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgCE/GWpf7gB7wf+Qa/XS2+qB/Fefvnl9Oarr75KbyoHxqamptKb1lqbmZkp7Vab0dH8v+GWlpbSm127dqU3zzzzTHrz1FNPpTet1Z4Dg/N0AQiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRpYHvPA2MjKy0u+FS+D9999Pb+6///70pnKkbmysdn+xcnxvNerqIF7Fxx9/nN7s2LFjBd7JnxvmZ9elQf7c+6YAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYBQu1A2hCoH+wa8BfgHXR3Wuuuuu9Kb1lo7fvx4elM5blfR5WG7rj4PXap8jipHCCs/p6NHj6Y39913X3rTWmvvvPNOelP5PKzGz9AgfFMAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQDC0F1JrVwhba21Xq+X3lSuQVYuVVY8+OCDpd3evXsv8Tv5c11di+WvqVz6rPj222/Tmx07dpReq3IldXFxsfRa/0S+KQAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIAzdQbzq0bTVdmzt7rvvLu3ee++9S/xOLp2ujrO11try8nJnrzXMKkcfK44dO5bePPnkk6XXeuWVV9Kbs2fPpjdr1qxJb6qH9yq7lfqM+6YAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAwdAfxVqPrr78+vfniiy9Kr1U9yJXV5QHC0dH8v10qx/cqB8a6ep2/suvCNddck970er3Sa91www3pzb59+9Kbubm59GY18E0BgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBhZHnAK1uVw18Vb731Vml30003pTcnTpxIbzZv3pze/PDDD+nNyZMn05vWWhsby984/PDDD9Obt99+O705e/ZsesP/hp07d6Y31113Xem1uvp9qhx93LRpU3rTWmuffvppevP555+nN4P8ufdNAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACEN3JfWDDz4o7f71r3+lNwsLC+nN3NxcejM7O5veVK6xttbaL7/8kt5MTEykN5VnNzpa+zfI66+/nt7s3r07vTl37lx6Mz4+nt5ULvq21tq9997byWvdeOON6c2pU6fSm23btqU3rbV25syZ9KbyGZ+amkpvLr/88vSmtdb27NmT3jzyyCPpjSupAKSIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAGPu738D/t7S0VNoNeNfvD86fP5/e9Pv99KZyRO/w4cPpTWu1A22nT59Ob2ZmZtKbLVu2pDettfb000+nNzt37kxvLly4kN5Uj/xVVD6vFy9eTG9+/PHH9KaicryxtdYmJyfTm++//z69mZ6eTm8qP6PWar9PK8U3BQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoAhKE7iLdmzZrSbt26denNmTNn0puJiYn0Zv369elN9dDar7/+mt7Mz8+nN71eL705cuRIetNaa6dOnUpvKs+88hmqHJzr8vjZ4uJiejM7O5veTE1NpTeV36XWWrvyyivTm8r/psqRzbGx2p/Uyt+ileKbAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAwtAdxLtw4UJpVznqtrS0lN5UjmQdP348ven3++lNdVc5Hlc5iDc+Pp7eVJ0/fz692bBhQ3qzdevW9ObQoUPpTWu1Y2uVZ1458nfy5Mn0pvIZaq217777Lr2Znp5Ob44ePZre3HLLLelNa60dO3astFsJvikAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACAM3UG8yiGz1lqbnJxMbyrH7SYmJtKbTZs2pTejo7VeV478LSwspDeV5zAzM5PetNba3NxcejMyMpLenD59Or05d+5celM9BLdu3br0pnIQb+3atenNxo0b05vKz7W12u/t5s2b05vK7+Ctt96a3rTW2vPPP1/arQTfFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgDB0V1IrVydba23Dhg3pTeWyauU6aL/fT2+qFyQrV1Ir1yDXrFmT3lSeXWu1K66zs7PpTeX9dbVprbXp6en0pnIttvLsxsbyf0oq11iru8rvU+U5zM/Ppzet1f5GrBTfFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEIbuIN7x48dLu/Hx8fSm1+ulN5UDY5VN5cBYa60tLi6WdlmVw3uV591a7VlUDvZVNpWfbeWzWn2tyqG1yutUfrZdPofz58+nN5Vnd/jw4fSmtda++eab0m4l+KYAQBAFAIIoABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAwdAfxTp069Xe/hf9qYWGhk9epHgsbHc13vnLcrqJyyKy12kG8ymZqaiq9qRwg7Op5t1Y7VFc5DFg9dlhR+d2o/F5MTk6mN+vXr09vWmvt3Llzpd1K8E0BgCAKAARRACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBh6A7iHTx4sLQ7ceLEJX4nf65yjKvf76c3XR4Yq7xWZVM5HteliYmJ9KZyILF6VLFy5G95eTm96epgX/V1Kp+jtWvXpjfHjh1Lb44cOZLeDBvfFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEIbuIN6BAwdKu23btqU3v/32W3pTOQRXOUpWPYg3zEfTRkdr/wapvFblOVQ2leNslcN71V3lGGNF5TNU/TzMzc2lN5VDllu2bElvvvzyy/Rm2PimAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRAGAIAoAhKG7klq5XNpaaz/99FN6MzU1ld78/vvv6U314mlF5aLoyMhIelO5cFm5pNla7cJl5aLoarwW2+XPqSuVn23l2V199dXpzbvvvpveDBvfFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAEIbuIF7V/v3705vt27enN5UDY10dZ2uttZmZmdIuq/IcFhcXS69VeX5jY/mPdr/fT28qz6FygLC12vOrPIfK8biK6nNYWFjoZDM5OZne7N27N70ZNr4pABBEAYAgCgAEUQAgiAIAQRQACKIAQBAFAIIoABBEAYAgCgAEUQAgjCwPeHmteryqK9PT0+nN119/nd5UDtVVDoxVD9tVDrRVNuPj4528Tmu1o24VXR3Eqx47rKi8VuXwXpfPofK3qNfrpTcHDhxIbx544IH0pkuDPHPfFAAIogBAEAUAgigAEEQBgCAKAARRACCIAgBBFAAIogBAEAUAgigAELq5NNaBixcvpje7du1Kb1544YX05ujRo+lN9Xhc5VhY5TDZwsJCelNVOShYMT8/n950dSCxqvL+KscOK69TPbJZ+ext3LgxvXnppZfSm6qufm8H4ZsCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCKAAQRpYHPLVXvWi42nz00Ufpzc0335zezM3NpTettdbr9dKbrVu3ll4L/uPnn39Ob6rXYqenp9ObPXv2pDePPvpoejPsBvlz75sCAEEUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQCCg3gduOOOO9Kba6+9tvRa69atS28WFxfTm36/n95UjvW1VvvsVTaV51A56lZ5naoBf73/oHKMcWZmJr2pfh5OnDiR3nzyySel11ptHMQDIEUUAAiiAEAQBQCCKAAQRAGAIAoABFEAIIgCAEEUAAiiAEAQBQDC2KD/YeWwFgD/W3xTACCIAgBBFAAIogBAEAUAgigAEEQBgCAKAARRACD8G2P+YWcjVAYbAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Normalize your data (train and test) between 0 and 1.\n",
        "Hint: This is a grayscale image has pixel values between 0 and 255."
      ],
      "metadata": {
        "id": "wvJTzCSbziZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "DHkLwW9ky3Hj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Now divide the training data into two: \n",
        "Validation images (first 5000 images from the initial training data) and Training images (rest of the images in your initial training data)."
      ],
      "metadata": {
        "id": "Rr6JoolTzvSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = train_images[:5000]\n",
        "val_labels = train_labels[:5000]\n",
        "train_images = train_images[5000:]\n",
        "train_labels = train_labels[5000:]"
      ],
      "metadata": {
        "id": "ewFOxHIUztsq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Initialize the weight and bias parameters of your model.\n"
      ],
      "metadata": {
        "id": "2J2aDc6q0K0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pWyOSq360Hv6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}